<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>rPPG Liveness Detection - Enterprise Demo</title>
<!-- TensorFlow.js -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>
<!-- MediaPipe Dependencies -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"
crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"
crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"
crossorigin="anonymous"></script>
<style>
* {
margin: 0;
padding: 0;
box-sizing: border-box;
}
body {
font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue',
Arial, sans-serif;
background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
min-height: 100vh;
padding: 20px;
}
.container {
max-width: 1600px;
margin: 0 auto;
background: white;
border-radius: 24px;
box-shadow: 0 20px 60px rgba(0,0,0,.3);
overflow: hidden;
}
.header {
background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
color: white;
padding: 32px 40px;
}
.header h1 {
font-size: 32px;
margin-bottom: 8px;
font-weight: 700;
}
.header p {
opacity: .9;
font-size: 14px;
}
.main-content {
display: grid;
grid-template-columns: 1.4fr 1fr;
gap: 30px;
padding: 30px;
}
.video-panel {
display: flex;
flex-direction: column;
gap: 20px;
}
.video-container {
position: relative;
background: #000;
border-radius: 16px;
overflow: hidden;
aspect-ratio: 4/3;
border: 4px solid #e0e0e0;
transition: all .3s;
}
.video-container.analyzing {
border-color: #ffc107;
box-shadow: 0 0 40px rgba(255,193,7,.4);
}
.video-container.verified {
border-color: #4caf50;
box-shadow: 0 0 40px rgba(76,175,80,.5);
}
.video-container.rejected {
border-color: #f44336;
box-shadow: 0 0 40px rgba(244,67,54,.5);
}
#webcam, #canvas {
position: absolute;
width: 100%;
height: 100%;
object-fit: cover;
transform: scaleX(-1);
}
.status-badge {
position: absolute;
top: 16px;
left: 16px;
background: rgba(0,0,0,.85);
backdrop-filter: blur(10px);
padding: 10px 16px;
border-radius: 8px;
z-index: 10;
display: flex;
align-items: center;
gap: 10px;
}
.status-dot {
width: 10px;
height: 10px;
border-radius: 50%;
animation: pulse 2s infinite;
}
@keyframes pulse {
0%, 100% { opacity: 1; transform: scale(1); }
50% { opacity: .6; transform: scale(.95); }
}
.dot-idle { background: #9e9e9e; }
.dot-analyzing { background: #ffc107; }
.dot-verified { background: #4caf50; }
.dot-rejected { background: #f44336; }
.status-text {
color: white;
font-weight: 600;
font-size: 13px;
}
.ppg-compact {
position: absolute;
bottom: 16px;
left: 16px;
right: 16px;
background: rgba(0,0,0,.9);
backdrop-filter: blur(10px);
padding: 12px 16px;
border-radius: 8px;
z-index: 10;
border: 2px solid rgba(76,175,80,.5);
}
.ppg-header {
display: flex;
justify-content: space-between;
margin-bottom: 8px;
color: white;
font-size: 12px;
}
.ppg-waveform {
height: 50px;
width: 100%;
}
.control-panel {
display: grid;
grid-template-columns: 1fr 1fr;
gap: 12px;
}
.btn {
padding: 16px 24px;
border: none;
border-radius: 10px;
font-size: 15px;
font-weight: 600;
cursor: pointer;
transition: all .2s;
}
.btn:disabled {
opacity: .5;
cursor: not-allowed;
}
.btn:not(:disabled):hover {
transform: translateY(-2px);
box-shadow: 0 8px 16px rgba(0,0,0,.2);
}
.btn-primary {
background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
color: white;
}
.btn-success {
background: linear-gradient(135deg, #56ab2f 0%, #a8e063 100%);
color: white;
}
.btn-danger {
background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%);
color: white;
}
.btn-full {
grid-column: 1 / -1;
}
.method-selector {
background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
border: 2px solid #2196f3;
border-radius: 12px;
padding: 20px;
margin-bottom: 20px;
}
.method-selector h3 {
color: #1565c0;
font-size: 16px;
margin-bottom: 16px;
font-weight: 700;
}
.method-option {
display: flex;
align-items: center;
gap: 12px;
padding: 12px;
background: white;
border-radius: 8px;
margin-bottom: 8px;
}
.method-badge {
padding: 4px 12px;
border-radius: 12px;
font-size: 11px;
font-weight: 600;
color: white;
margin-left: auto;
}
.badge-fast { background: #ffc107; }
.badge-accurate { background: #4caf50; }
.badge-best { background: #9c27b0; }
.neural-status {
margin-top: 12px;
padding: 12px;
background: rgba(33, 150, 243, 0.1);
border-radius: 8px;
font-size: 13px;
color: #1565c0;
max-height: 200px;
overflow-y: auto;
}
.info-panel {
display: flex;
flex-direction: column;
gap: 20px;
}
.card {
background: #f8f9fa;
border-radius: 12px;
padding: 20px;
border-left: 4px solid #667eea;
}
.card-title {
font-size: 16px;
font-weight: 700;
color: #2c3e50;
margin-bottom: 16px;
}
.progress-ring {
position: relative;
width: 120px;
height: 120px;
margin: 0 auto 16px;
}
.progress-ring svg {
transform: rotate(-90deg);
}
.progress-ring-circle {
stroke: #e0e0e0;
fill: none;
stroke-width: 8;
}
.progress-ring-fill {
stroke: #667eea;
fill: none;
stroke-width: 8;
stroke-linecap: round;
transition: stroke-dashoffset .5s;
}
.progress-text {
position: absolute;
top: 50%;
left: 50%;
transform: translate(-50%, -50%);
text-align: center;
}
.progress-value {
font-size: 32px;
font-weight: 700;
color: #667eea;
}
.metric-grid {
display: grid;
grid-template-columns: repeat(3, 1fr);
gap: 12px;
}
.metric-box {
background: white;
padding: 16px;
border-radius: 10px;
text-align: center;
}
.metric-value {
font-size: 28px;
font-weight: 700;
color: #667eea;
}
.metric-label {
font-size: 11px;
color: #666;
text-transform: uppercase;
}
.stat-row {
display: flex;
justify-content: space-between;
padding: 12px 0;
border-bottom: 1px solid #e0e0e0;
}
.stat-row:last-child {
border-bottom: none;
}
.test-item {
display: flex;
justify-content: space-between;
padding: 10px;
background: white;
border-radius: 8px;
margin-bottom: 8px;
}
.test-status {
padding: 4px 12px;
border-radius: 12px;
font-size: 12px;
font-weight: 600;
}
.status-pass {
background: #d4edda;
color: #155724;
}
.status-fail {
background: #f8d7da;
color: #721c24;
}
.status-pending {
background: #e0e0e0;
color: #666;
}
.alert {
padding: 16px 20px;
border-radius: 10px;
font-size: 14px;
margin-bottom: 10px;
}
.alert-success {
background: #d4edda;
color: #155724;
}
.alert-error {
background: #f8d7da;
color: #721c24;
}
.alert-warning {
background: #fff3cd;
color: #856404;
}
.loading-overlay {
position: fixed;
top: 0;
left: 0;
right: 0;
bottom: 0;
background: rgba(0,0,0,.9);
display: none;
align-items: center;
justify-content: center;
z-index: 9999;
color: white;
flex-direction: column;
gap: 20px;
}
.loading-content {
text-align: center;
max-width: 600px;
padding: 20px;
}
.spinner {
width: 50px;
height: 50px;
border: 4px solid #333;
border-top-color: #667eea;
border-radius: 50%;
animation: spin 1s linear infinite;
margin: 0 auto 20px;
}
@keyframes spin {
to { transform: rotate(360deg); }
}
.loading-log {
background: rgba(255,255,255,0.1);
padding: 15px;
border-radius: 8px;
margin-top: 20px;
max-height: 300px;
overflow-y: auto;
text-align: left;
font-family: monospace;
font-size: 12px;
}
.log-entry {
margin: 5px 0;
padding: 5px;
border-left: 3px solid #667eea;
padding-left: 10px;
}
.log-error {
border-left-color: #f44336;
color: #ff6b6b;
}
.log-success {
border-left-color: #4caf50;
color: #81c784;
}
.log-warning {
border-left-color: #ffc107;
color: #ffd54f;
}
@media (max-width: 1200px) {
.main-content {
grid-template-columns: 1fr;
}
}
</style>
</head>
<body>
<div id="loadingOverlay" class="loading-overlay">
<div class="loading-content">
<div class="spinner"></div>
<div style="font-size:18px;font-weight:600" id="loadTitle">Initializing...</div>
<div style="font-size:14px;opacity:.8;margin-top:10px" id="loadText">Loading...</div>
<div class="loading-log" id="loadingLog"></div>
</div>
</div>
<div class="container">
<div class="header">
<h1>üõ° Advanced rPPG Liveness Detection</h1>
<p>Enterprise-Grade Anti-Spoofing System | Two-Input Neural Network | 98.27% AUC</p>
</div>
<div class="main-content">
<div class="video-panel">
<div class="video-container" id="videoContainer">
<video id="webcam" autoplay playsinline muted></video>
<canvas id="canvas"></canvas>
<div class="status-badge">
<span class="status-dot dot-idle" id="statusDot"></span>
<span class="status-text" id="statusText">READY</span>
</div>
<div class="ppg-compact">
<div class="ppg-header">
<span>BVP: <span id="compactBVP">--</span></span>
<span>Samples: <span id="compactSamples">0</span></span>
</div>
<canvas id="ppgWaveform" class="ppg-waveform"></canvas>
</div>
</div>
<div class="control-panel">
<button id="startBtn" class="btn btn-primary btn-full">üé• Start Camera</button>
<button id="analyzeBtn" class="btn btn-success" disabled>üîç Start Analysis</button>
<button id="stopBtn" class="btn btn-danger" disabled>‚èπ Stop</button>
</div>
<div class="method-selector">
<h3>üî¨ Detection Method</h3>
<div class="method-option">
<input type="radio" id="methodGMM" name="detectionMethod" value="gmm" checked>
<label for="methodGMM">GMM Classifier (Fast)</label>
<span class="method-badge badge-fast">FAST</span>
</div>
<div class="method-option">
<input type="radio" id="methodNeural" name="detectionMethod" value="neural">
<label for="methodNeural">Neural Network (Accurate)</label>
<span class="method-badge badge-accurate">98.27% AUC</span>
</div>
<div class="method-option">
<input type="radio" id="methodHybrid" name="detectionMethod" value="hybrid">
<label for="methodHybrid">Hybrid Mode (Recommended)</label>
<span class="method-badge badge-best">BEST</span>
</div>
<div class="neural-status" id="neuralStatus">
üîÑ Neural network loading...
</div>
</div>
<div id="alertBox"></div>
</div>
<div class="info-panel">
<div class="card">
<div class="card-title">üéØ Liveness Confidence</div>
<div class="progress-ring">
<svg width="120" height="120">
<circle class="progress-ring-circle" cx="60" cy="60" r="52"></circle>
<circle id="progressCircle" class="progress-ring-fill" cx="60" cy="60" r="52"
stroke-dasharray="326.73" stroke-dashoffset="326.73"></circle>
</svg>
<div class="progress-text">
<div class="progress-value" id="confidenceValue">0%</div>
</div>
</div>
<div class="metric-grid">
<div class="metric-box">
<div class="metric-value" id="gmmScore">--</div>
<div class="metric-label">GMM Score</div>
</div>
<div class="metric-box">
<div class="metric-value" id="neuralScore">--</div>
<div class="metric-label">Neural Score</div>
</div>
<div class="metric-box">
<div class="metric-value" id="depthScore">--</div>
<div class="metric-label">3D Depth</div>
</div>
</div>
</div>
<div class="card">
<div class="card-title">üìä Detection Metrics</div>
<div class="stat-row">
<span>Analysis Time:</span>
<span id="duration">0.0s</span>
</div>
<div class="stat-row">
<span>Method:</span>
<span id="currentMethod">GMM Classifier (Fast)</span>
</div>
<div class="stat-row">
<span>1st Deriv (√ó10‚Åª¬≥):</span>
<span id="derivValue">--</span>
</div>
<div class="stat-row">
<span>Embedding:</span>
<span id="embeddingConsistency">--</span>
</div>
</div>
<div class="card">
<div class="card-title">üß™ Anti-Spoofing Tests</div>
<div class="test-item">
<span>‚úì GMM Derivative</span>
<span class="test-status status-pending" id="test1">Pending</span>
</div>
<div class="test-item">
<span>‚úì Neural Embedding</span>
<span class="test-status status-pending" id="test2">Pending</span>
</div>
<div class="test-item">
<span>‚úì Embedding Consistency</span>
<span class="test-status status-pending" id="test3">Pending</span>
</div>
<div class="test-item">
<span>‚úì Temporal Depth</span>
<span class="test-status status-pending" id="test4">Pending</span>
</div>
</div>
</div>
</div>
</div>
<script>
// ================================================================================
// LOGGING SYSTEM
// ================================================================================
const LOG = {
entries: [],
add: function(message, type = 'info') {
const timestamp = new Date().toLocaleTimeString();
const entry = { timestamp, message, type };
this.entries.push(entry);
console.log(`[${timestamp}] ${message}`);
this.updateUI();
},
updateUI: function() {
const logContainer = document.getElementById('loadingLog');
const neuralStatus = document.getElementById('neuralStatus');
if (logContainer && logContainer.parentElement.style.display !== 'none') {
const html = this.entries.slice(-10).map(entry => {
const className = entry.type === 'error' ? 'log-error' : 
                          entry.type === 'success' ? 'log-success' : 
                          entry.type === 'warning' ? 'log-warning' : '';
return `<div class="log-entry ${className}">[${entry.timestamp}] ${entry.message}</div>`;
}).join('');
logContainer.innerHTML = html;
logContainer.scrollTop = logContainer.scrollHeight;
}
if (neuralStatus) {
const recent = this.entries.slice(-5).map(e => e.message).join('<br>');
neuralStatus.innerHTML = recent;
}
}
};

// ================================================================================
// CONFIGURATION
// ================================================================================
const MODEL_URL = 'https://aero34317-coder.github.io/PPG_tfjs_model/model.json';
const CFG = {
FPS: 30,
MIN_SAMPLES: 150,
NEURAL_SAMPLES: 1024,
CONFIDENCE_THRESHOLD: 45,
BANDPASS_LOW: 0.5,
BANDPASS_HIGH: 8.0,
GMM_FAKE_THRESHOLD: 1300,
GMM_REAL_THRESHOLD: 2000,
DEPTH_TEMPORAL_THRESHOLD: 0.00015,
EMBEDDING_CONSISTENCY_THRESHOLD: 0.85,
LOAD_TIMEOUT: 60000 // 60 seconds
};

// ================================================================================
// STATE
// ================================================================================
const STATE = {
faceMesh: null,
videoStream: null,
animationFrameId: null,
isAnalyzing: false,
startTime: null,
neuralModel: null,
neuralModelLoaded: false,
detectionMethod: 'gmm',
rSignal: [],
gSignal: [],
bSignal: [],
posSignal: [],
depthHistory: [],
firstDerivVariance: 0,
embeddings: [],
embeddingConsistency: 0,
temporalDepthVariance: 0,
isStaticDepth: false,
metricsInterval: null
};

// ================================================================================
// DOM ELEMENTS
// ================================================================================
const E = {
webcam: document.getElementById('webcam'),
canvas: document.getElementById('canvas'),
videoContainer: document.getElementById('videoContainer'),
statusDot: document.getElementById('statusDot'),
statusText: document.getElementById('statusText'),
ppgWaveform: document.getElementById('ppgWaveform'),
compactBVP: document.getElementById('compactBVP'),
compactSamples: document.getElementById('compactSamples'),
startBtn: document.getElementById('startBtn'),
analyzeBtn: document.getElementById('analyzeBtn'),
stopBtn: document.getElementById('stopBtn'),
alertBox: document.getElementById('alertBox'),
confidenceValue: document.getElementById('confidenceValue'),
progressCircle: document.getElementById('progressCircle'),
gmmScore: document.getElementById('gmmScore'),
neuralScore: document.getElementById('neuralScore'),
depthScore: document.getElementById('depthScore'),
duration: document.getElementById('duration'),
derivValue: document.getElementById('derivValue'),
embeddingConsistency: document.getElementById('embeddingConsistency'),
currentMethod: document.getElementById('currentMethod'),
test1: document.getElementById('test1'),
test2: document.getElementById('test2'),
test3: document.getElementById('test3'),
test4: document.getElementById('test4'),
loadingOverlay: document.getElementById('loadingOverlay'),
loadTitle: document.getElementById('loadTitle'),
loadText: document.getElementById('loadText'),
neuralStatus: document.getElementById('neuralStatus')
};

// ================================================================================
// UTILITY FUNCTIONS
// ================================================================================
function calculateMean(arr) {
if (!arr || arr.length === 0) return 0;
return arr.reduce((sum, val) => sum + val, 0) / arr.length;
}

function calculateStd(arr) {
if (!arr || arr.length === 0) return 0;
const mean = calculateMean(arr);
const variance = arr.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / arr.length;
return Math.sqrt(variance);
}

function normalizeSignal(arr) {
const mean = calculateMean(arr);
const std = calculateStd(arr);
if (std === 0) return arr.map(() => 0);
return arr.map(val => (val - mean) / std);
}

function cosineSimilarity(vecA, vecB) {
if (vecA.length !== vecB.length) return 0;
let dotProduct = 0, normA = 0, normB = 0;
for (let i = 0; i < vecA.length; i++) {
dotProduct += vecA[i] * vecB[i];
normA += vecA[i] * vecA[i];
normB += vecB[i] * vecB[i];
}
normA = Math.sqrt(normA);
normB = Math.sqrt(normB);
return (normA > 0 && normB > 0) ? dotProduct / (normA * normB) : 0;
}

// ================================================================================
// SIGNAL PROCESSING
// ================================================================================
function lightBandpassFilter(signal, fps, lowCut, highCut) {
if (signal.length < 10) return signal;
const mean = calculateMean(signal);
let filtered = signal.map(val => val - mean);
const windowSize = Math.max(3, Math.floor(fps / highCut));
const smoothed = [];
for (let i = 0; i < filtered.length; i++) {
const start = Math.max(0, i - Math.floor(windowSize / 2));
const end = Math.min(filtered.length, i + Math.ceil(windowSize / 2));
smoothed.push(calculateMean(filtered.slice(start, end)));
}
return smoothed;
}

function extractPPG(image, landmarks) {
const canvas = document.createElement('canvas');
const ctx = canvas.getContext('2d');
canvas.width = image.width;
canvas.height = image.height;
ctx.drawImage(image, 0, 0);
const regions = [
[10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288],
[205, 50, 123, 132, 177, 147, 187, 207, 216, 206],
[425, 280, 352, 361, 401, 376, 411, 427, 436, 426]
];
let totalR = 0, totalG = 0, totalB = 0, pixelCount = 0;
for (const region of regions) {
for (const idx of region) {
const point = landmarks[idx];
const x = Math.floor(point.x * canvas.width);
const y = Math.floor(point.y * canvas.height);
if (x >= 0 && x < canvas.width && y >= 0 && y < canvas.height) {
const pixel = ctx.getImageData(x, y, 1, 1).data;
totalR += pixel[0];
totalG += pixel[1];
totalB += pixel[2];
pixelCount++;
}
}
}
if (pixelCount === 0) return { r: 0, g: 0, b: 0 };
return {
r: totalR / pixelCount,
g: totalG / pixelCount,
b: totalB / pixelCount
};
}

function processPOS() {
if (STATE.rSignal.length < CFG.MIN_SAMPLES) return null;
const rNorm = normalizeSignal(STATE.rSignal);
const gNorm = normalizeSignal(STATE.gSignal);
const bNorm = normalizeSignal(STATE.bSignal);
const posRaw = [];
for (let i = 0; i < rNorm.length; i++) {
posRaw.push(3.0 * gNorm[i] - 1.5 * rNorm[i] - 1.5 * bNorm[i]);
}
STATE.posSignal = lightBandpassFilter(posRaw, CFG.FPS, CFG.BANDPASS_LOW, CFG.BANDPASS_HIGH);
return STATE.posSignal;
}

function analyzeWaveformDerivatives() {
if (STATE.rSignal.length < 90) return null;
const recentR = STATE.rSignal.slice(-90);
const recentG = STATE.gSignal.slice(-90);
const recentB = STATE.bSignal.slice(-90);
const meanR = calculateMean(recentR);
const meanG = calculateMean(recentG);
const meanB = calculateMean(recentB);
const normR = recentR.map(v => v - meanR);
const normG = recentG.map(v => v - meanG);
const normB = recentB.map(v => v - meanB);
const rawPOS = [];
for (let i = 0; i < normR.length; i++) {
rawPOS.push(3.0 * normG[i] - 1.5 * normR[i] - 1.5 * normB[i]);
}
const firstDeriv = [];
for (let i = 1; i < rawPOS.length; i++) {
firstDeriv.push(Math.abs(rawPOS[i] - rawPOS[i - 1]));
}
STATE.firstDerivVariance = calculateMean(firstDeriv) * 1000;
return { firstDerivVariance: STATE.firstDerivVariance };
}

// ================================================================================
// MORPHOLOGICAL FEATURES
// ================================================================================
function findPeaks(signal) {
const peaks = [];
const minDistance = Math.floor(0.4 * CFG.FPS);
let lastPeak = -minDistance;
for (let i = 1; i < signal.length - 1; i++) {
if (signal[i] > signal[i-1] && signal[i] > signal[i+1]) {
if (i - lastPeak >= minDistance && signal[i] > 0.5) {
peaks.push(i);
lastPeak = i;
}
}
}
return peaks;
}

function extractMorphologicalFeatures(signal) {
const features = new Array(20).fill(0);
try {
const peaks = findPeaks(signal);
if (peaks.length < 2) return features;
const ppis = [];
for (let i = 1; i < peaks.length; i++) {
ppis.push((peaks[i] - peaks[i-1]) / CFG.FPS);
}
if (ppis.length > 0) {
features[0] = calculateMean(ppis);
features[1] = calculateStd(ppis);
features[2] = Math.max(...ppis);
features[3] = Math.min(...ppis);
}
const amplitudes = peaks.map(p => signal[p]);
features[6] = calculateMean(amplitudes);
features[7] = calculateStd(amplitudes);
features[15] = calculateMean(signal);
features[16] = calculateStd(signal);
features[17] = Math.max(...signal);
features[18] = Math.min(...signal);
} catch (error) {
console.error('Feature extraction error:', error);
}
return features;
}

// ================================================================================
// NEURAL NETWORK - SIMPLIFIED WITH BETTER ERROR HANDLING
// ================================================================================
async function loadNeuralModel() {
const startTime = Date.now();

try {
LOG.add('üöÄ Starting neural network load...', 'info');
E.loadText.textContent = 'Step 1/6: Fetching model.json...';

// Set timeout
const timeoutPromise = new Promise((_, reject) => {
setTimeout(() => reject(new Error('Load timeout (60s)')), CFG.LOAD_TIMEOUT);
});

// Try to load with TensorFlow.js built-in loader FIRST (simplest approach)
LOG.add('üì• Attempting direct TF.js load...', 'info');
E.loadText.textContent = 'Step 2/6: Loading with TensorFlow.js...';

try {
STATE.neuralModel = await Promise.race([
tf.loadLayersModel(MODEL_URL),
timeoutPromise
]);
STATE.neuralModelLoaded = true;
LOG.add('‚úÖ Model loaded via direct TF.js!', 'success');
} catch (directError) {
LOG.add(`‚ö†Ô∏è Direct load failed: ${directError.message}`, 'warning');
LOG.add('üîß Trying compatibility fix...', 'info');
E.loadText.textContent = 'Step 3/6: Applying Keras 3.x fix...';

// Fallback: Manual load with Keras 3.x fix
const modelJson = await fetchWithRetry(MODEL_URL);
LOG.add('‚úÖ model.json fetched', 'success');
E.loadText.textContent = 'Step 4/6: Fixing inbound_nodes...';

// Apply Keras 3.x compatibility fix
let fixCount = 0;
if (modelJson.modelTopology?.model_config?.config?.layers) {
modelJson.modelTopology.model_config.config.layers.forEach(layer => {
if (layer.inbound_nodes && Array.isArray(layer.inbound_nodes)) {
const fixedNodes = layer.inbound_nodes.map(node => {
if (node && typeof node === 'object' && 'args' in node) {
fixCount++;
return node.args;
}
return node;
});
layer.inbound_nodes = fixedNodes;
}
});
LOG.add(`‚úÖ Fixed ${fixCount} inbound_nodes`, 'success');
}
E.loadText.textContent = 'Step 5/6: Loading weights...';
const modelDir = MODEL_URL.substring(0, MODEL_URL.lastIndexOf('/') + 1);
// Prepare weight paths
if (modelJson.weightsManifest) {
modelJson.weightsManifest.forEach(manifest => {
manifest.paths = manifest.paths.map(path => {
if (!path.startsWith('http')) {
return modelDir + path;
}
return path;
});
});
}
// Fetch weights
LOG.add(`üì¶ Loading ${modelJson.weightsManifest[0].paths.length} weight files...`, 'info');
const weightBuffers = [];
let loadedBytes = 0;
for (const manifest of modelJson.weightsManifest) {
for (const path of manifest.paths) {
const fileName = path.split('/').pop();
LOG.add(`‚¨áÔ∏è Fetching ${fileName}...`, 'info');
const response = await fetchWithRetry(path);
const buffer = await response.arrayBuffer();
loadedBytes += buffer.byteLength;
weightBuffers.push(buffer);
LOG.add(`‚úÖ ${fileName} loaded (${(buffer.byteLength/1024/1024).toFixed(2)}MB)`, 'success');
}
}
// Concatenate weights
let totalSize = 0;
weightBuffers.forEach(buf => totalSize += buf.byteLength);
const concatenated = new Uint8Array(totalSize);
let offset = 0;
weightBuffers.forEach(buf => {
concatenated.set(new Uint8Array(buf), offset);
offset += buf.byteLength;
});
LOG.add(`‚úÖ All weights loaded (${(totalSize/1024/1024).toFixed(2)}MB)`, 'success');
E.loadText.textContent = 'Step 6/6: Initializing model...';
// Create model artifacts
const modelArtifacts = {
modelTopology: modelJson.modelTopology,
weightSpecs: modelJson.weightsManifest[0].weights,
weightData: concatenated.buffer,
format: modelJson.format,
generatedBy: modelJson.generatedBy,
convertedBy: modelJson.convertedBy
};
// Load into TF.js
STATE.neuralModel = await tf.loadLayersModel(tf.io.fromMemory(modelArtifacts));
STATE.neuralModelLoaded = true;
LOG.add('‚úÖ Model loaded with compatibility fix!', 'success');
}
// Verify model
if (STATE.neuralModel.inputs.length !== 2) {
throw new Error(`Expected 2 inputs, got ${STATE.neuralModel.inputs.length}`);
}
LOG.add(`‚úÖ Model verified: 2 inputs, 1 output`, 'success');
LOG.add(`Input 1: ${STATE.neuralModel.inputs[0].shape}`, 'info');
LOG.add(`Input 2: ${STATE.neuralModel.inputs[1].shape}`, 'info');
// Warm up
LOG.add('üî• Warming up model...', 'info');
const dummySignal = tf.zeros([1, 1024, 1]);
const dummyFeatures = tf.zeros([1, 20, 1]);
const warmup = STATE.neuralModel.predict([dummySignal, dummyFeatures]);
warmup.dispose();
dummySignal.dispose();
dummyFeatures.dispose();
const elapsed = ((Date.now() - startTime) / 1000).toFixed(2);
LOG.add(`‚úÖ Neural network ready! (${elapsed}s)`, 'success');
E.neuralStatus.innerHTML = `‚úÖ <strong>Neural network loaded!</strong><br>98.27% AUC | ${elapsed}s load time`;
E.neuralStatus.style.background = 'rgba(76, 175, 80, 0.1)';
E.neuralStatus.style.color = '#2e7d32';
// Enable hybrid mode
document.getElementById('methodNeural').disabled = false;
document.getElementById('methodHybrid').disabled = false;
} catch (error) {
const elapsed = ((Date.now() - startTime) / 1000).toFixed(2);
LOG.add(`‚ùå Model load failed: ${error.message}`, 'error');
LOG.add(`Stack: ${error.stack}`, 'error');
E.neuralStatus.innerHTML = `‚ùå <strong>Neural network failed to load</strong><br><small>${error.message}</small><br><br>‚ö†Ô∏è GMM mode still available`;
E.neuralStatus.style.background = 'rgba(244, 67, 54, 0.1)';
E.neuralStatus.style.color = '#c62828';
STATE.neuralModelLoaded = false;
// Disable neural/hybrid modes
document.getElementById('methodNeural').disabled = true;
document.getElementById('methodHybrid').disabled = true;
document.getElementById('methodGMM').checked = true;
showAlert('Neural network unavailable. Using GMM mode.', 'warning');
}
}

async function fetchWithRetry(url, retries = 3) {
for (let i = 0; i < retries; i++) {
try {
const response = await fetch(url);
if (!response.ok) {
throw new Error(`HTTP ${response.status}: ${response.statusText}`);
}
return response;
} catch (error) {
LOG.add(`‚ö†Ô∏è Fetch attempt ${i + 1}/${retries} failed: ${error.message}`, 'warning');
if (i === retries - 1) throw error;
await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
}
}
}

// ================================================================================
// NEURAL PREDICTION
// ================================================================================
async function predictWithNeural(signal, features) {
if (!STATE.neuralModelLoaded || !STATE.neuralModel) {
return null;
}
try {
let processedSignal = [...signal];
if (processedSignal.length < CFG.NEURAL_SAMPLES) {
const padding = new Array(CFG.NEURAL_SAMPLES - processedSignal.length).fill(0);
processedSignal = [...processedSignal, ...padding];
} else if (processedSignal.length > CFG.NEURAL_SAMPLES) {
processedSignal = processedSignal.slice(0, CFG.NEURAL_SAMPLES);
}
const normalized = normalizeSignal(processedSignal);
let processedFeatures = [...features];
if (processedFeatures.length < 20) {
const padding = new Array(20 - processedFeatures.length).fill(0);
processedFeatures = [...processedFeatures, ...padding];
} else if (processedFeatures.length > 20) {
processedFeatures = processedFeatures.slice(0, 20);
}
const signalTensor = tf.tensor3d([normalized.map(v => [v])], [1, 1024, 1]);
const featureTensor = tf.tensor3d([processedFeatures.map(v => [v])], [1, 20, 1]);
const embedding = STATE.neuralModel.predict([signalTensor, featureTensor]);
const embeddingArray = await embedding.array();
signalTensor.dispose();
featureTensor.dispose();
embedding.dispose();
return embeddingArray[0];
} catch (error) {
console.error('Neural prediction error:', error);
return null;
}
}

// ================================================================================
// DEPTH ANALYSIS
// ================================================================================
function calculate3DDepthVariance(landmarks) {
if (!landmarks || landmarks.length === 0) return 0;
const noseTip = landmarks[4];
const leftCheek = landmarks[234];
const rightCheek = landmarks[454];
const depth = Math.abs(noseTip.z - ((leftCheek.z + rightCheek.z) / 2));
STATE.depthHistory.push(depth);
if (STATE.depthHistory.length > 30) {
STATE.depthHistory.shift();
}
if (STATE.depthHistory.length < 10) return 0;
const variance = calculateStd(STATE.depthHistory);
STATE.temporalDepthVariance = variance;
STATE.isStaticDepth = variance < CFG.DEPTH_TEMPORAL_THRESHOLD;
return variance;
}

// ================================================================================
// CLASSIFICATION
// ================================================================================
function classifyWithGMM() {
const deriv = STATE.firstDerivVariance;
if (deriv < CFG.GMM_FAKE_THRESHOLD) {
return { class: 'fake', confidence: 0, score: deriv };
} else if (deriv > CFG.GMM_REAL_THRESHOLD) {
return { class: 'real', confidence: 100, score: deriv };
} else {
const range = CFG.GMM_REAL_THRESHOLD - CFG.GMM_FAKE_THRESHOLD;
const position = deriv - CFG.GMM_FAKE_THRESHOLD;
const confidence = Math.round((position / range) * 100);
return { class: 'uncertain', confidence, score: deriv };
}
}

async function performHybridAnalysis() {
if (STATE.posSignal.length < CFG.MIN_SAMPLES) return null;
const derivResult = analyzeWaveformDerivatives();
const gmmResult = classifyWithGMM();
const features = extractMorphologicalFeatures(STATE.posSignal);
let neuralResult = null;
let embeddingConsistency = 0;
if (STATE.neuralModelLoaded) {
const embedding = await predictWithNeural(STATE.posSignal, features);
if (embedding) {
STATE.embeddings.push(embedding);
if (STATE.embeddings.length > 10) {
STATE.embeddings.shift();
}
if (STATE.embeddings.length >= 2) {
let totalSim = 0;
for (let i = 1; i < STATE.embeddings.length; i++) {
totalSim += cosineSimilarity(STATE.embeddings[i-1], STATE.embeddings[i]);
}
embeddingConsistency = totalSim / (STATE.embeddings.length - 1);
STATE.embeddingConsistency = embeddingConsistency;
}
const embeddingNorm = Math.sqrt(embedding.reduce((sum, v) => sum + v * v, 0));
const neuralConfidence = Math.min(100, Math.max(0, (embeddingNorm - 5) * 10));
neuralResult = { confidence: neuralConfidence, norm: embeddingNorm };
}
}
const depthTest = !STATE.isStaticDepth;
let finalConfidence = 0;
let finalClass = 'uncertain';
if (STATE.detectionMethod === 'gmm') {
finalConfidence = gmmResult.confidence;
finalClass = gmmResult.class;
} else if (STATE.detectionMethod === 'neural' && neuralResult) {
finalConfidence = neuralResult.confidence;
finalClass = finalConfidence > 50 ? 'real' : 'fake';
} else if (STATE.detectionMethod === 'hybrid') {
const gmmWeight = 0.4;
const neuralWeight = 0.4;
const consistencyWeight = 0.2;
let score = gmmResult.confidence * gmmWeight;
if (neuralResult) {
score += neuralResult.confidence * neuralWeight;
score += embeddingConsistency * 100 * consistencyWeight;
} else {
score = gmmResult.confidence;
}
finalConfidence = Math.round(score);
if (finalConfidence > 70) finalClass = 'real';
else if (finalConfidence < 30) finalClass = 'fake';
else finalClass = 'uncertain';
}
return {
class: finalClass,
confidence: finalConfidence,
gmm: gmmResult,
neural: neuralResult,
embeddingConsistency,
depthTest,
features
};
}

// ================================================================================
// UI UPDATES
// ================================================================================
function showAlert(message, type = 'success') {
const alertClass = `alert-${type}`;
E.alertBox.innerHTML = `<div class="alert ${alertClass}">${message}</div>`;
setTimeout(() => {
E.alertBox.innerHTML = '';
}, 5000);
}

function updateUI(result) {
if (!result) return;
E.confidenceValue.textContent = `${result.confidence}%`;
const circumference = 326.73;
const offset = circumference - (result.confidence / 100) * circumference;
E.progressCircle.style.strokeDashoffset = offset;
E.gmmScore.textContent = result.gmm.score.toFixed(1);
E.neuralScore.textContent = result.neural ? result.neural.norm.toFixed(2) : '--';
E.depthScore.textContent = (STATE.temporalDepthVariance * 1000).toFixed(2);
E.derivValue.textContent = result.gmm.score.toFixed(1);
E.embeddingConsistency.textContent = (result.embeddingConsistency * 100).toFixed(1) + '%';
E.test1.textContent = result.gmm.confidence > 50 ? 'Pass' : 'Fail';
E.test1.className = `test-status ${result.gmm.confidence > 50 ? 'status-pass' : 'status-fail'}`;
E.test2.textContent = result.neural ? 'Pass' : 'Pending';
E.test2.className = `test-status ${result.neural ? 'status-pass' : 'status-pending'}`;
E.test3.textContent = result.embeddingConsistency > CFG.EMBEDDING_CONSISTENCY_THRESHOLD ? 'Pass' : 'Fail';
E.test3.className = `test-status ${result.embeddingConsistency > CFG.EMBEDDING_CONSISTENCY_THRESHOLD ? 'status-pass' : 'status-fail'}`;
E.test4.textContent = result.depthTest ? 'Pass' : 'Fail';
E.test4.className = `test-status ${result.depthTest ? 'status-pass' : 'status-fail'}`;
E.videoContainer.classList.remove('analyzing', 'verified', 'rejected');
if (result.class === 'real' && result.confidence > 70) {
E.videoContainer.classList.add('verified');
E.statusDot.className = 'status-dot dot-verified';
E.statusText.textContent = 'VERIFIED REAL';
} else if (result.class === 'fake') {
E.videoContainer.classList.add('rejected');
E.statusDot.className = 'status-dot dot-rejected';
E.statusText.textContent = 'FAKE DETECTED';
} else {
E.videoContainer.classList.add('analyzing');
E.statusDot.className = 'status-dot dot-analyzing';
E.statusText.textContent = 'ANALYZING';
}
}

function drawPPGWaveform() {
const canvas = E.ppgWaveform;
const ctx = canvas.getContext('2d');
canvas.width = canvas.offsetWidth;
canvas.height = canvas.offsetHeight;
ctx.clearRect(0, 0, canvas.width, canvas.height);
if (STATE.posSignal.length < 2) return;
const displaySamples = Math.min(STATE.posSignal.length, 150);
const signal = STATE.posSignal.slice(-displaySamples);
const normalized = normalizeSignal(signal);
const padding = 5;
const availableHeight = canvas.height - 2 * padding;
ctx.strokeStyle = '#4caf50';
ctx.lineWidth = 2;
ctx.beginPath();
for (let i = 0; i < normalized.length; i++) {
const x = (i / (normalized.length - 1)) * canvas.width;
const y = padding + availableHeight / 2 - (normalized[i] * availableHeight / 4);
if (i === 0) ctx.moveTo(x, y);
else ctx.lineTo(x, y);
}
ctx.stroke();
const peaks = findPeaks(signal);
if (peaks.length >= 2) {
const avgInterval = (peaks[peaks.length - 1] - peaks[0]) / (peaks.length - 1) / CFG.FPS;
const bpm = Math.round(60 / avgInterval);
E.compactBVP.textContent = `${bpm} BPM`;
} else {
E.compactBVP.textContent = '--';
}
}

// ================================================================================
// CAMERA & FACE DETECTION
// ================================================================================
async function startCamera() {
try {
E.loadingOverlay.style.display = 'flex';
E.loadTitle.textContent = 'Starting Camera...';
E.loadText.textContent = 'Requesting camera access...';
LOG.add('üì∑ Requesting camera...', 'info');
const stream = await navigator.mediaDevices.getUserMedia({
video: { width: 1280, height: 720, facingMode: 'user' }
});
E.webcam.srcObject = stream;
STATE.videoStream = stream;
await new Promise(resolve => {
E.webcam.onloadedmetadata = resolve;
});
LOG.add('‚úÖ Camera started', 'success');
E.loadText.textContent = 'Initializing face detection...';
LOG.add('üé≠ Initializing MediaPipe...', 'info');
STATE.faceMesh = new FaceMesh({
locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
});
STATE.faceMesh.setOptions({
maxNumFaces: 1,
refineLandmarks: true,
minDetectionConfidence: 0.5,
minTrackingConfidence: 0.5
});
STATE.faceMesh.onResults(onFaceResults);
LOG.add('‚úÖ Face detection ready', 'success');
E.loadingOverlay.style.display = 'none';
E.startBtn.disabled = true;
E.analyzeBtn.disabled = false;
E.stopBtn.disabled = false;
showAlert('Camera started successfully!', 'success');
} catch (error) {
LOG.add(`‚ùå Camera error: ${error.message}`, 'error');
E.loadingOverlay.style.display = 'none';
showAlert('Camera access denied: ' + error.message, 'error');
}
}

function onFaceResults(results) {
const canvas = E.canvas;
const ctx = canvas.getContext('2d');
canvas.width = E.webcam.videoWidth;
canvas.height = E.webcam.videoHeight;
ctx.clearRect(0, 0, canvas.width, canvas.height);
if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
const landmarks = results.multiFaceLandmarks[0];
ctx.fillStyle = '#4caf50';
landmarks.forEach(point => {
ctx.beginPath();
ctx.arc(point.x * canvas.width, point.y * canvas.height, 1, 0, 2 * Math.PI);
ctx.fill();
});
if (STATE.isAnalyzing) {
const ppg = extractPPG(E.webcam, landmarks);
STATE.rSignal.push(ppg.r);
STATE.gSignal.push(ppg.g);
STATE.bSignal.push(ppg.b);
calculate3DDepthVariance(landmarks);
processPOS();
drawPPGWaveform();
E.compactSamples.textContent = STATE.posSignal.length;
if (STATE.posSignal.length >= CFG.MIN_SAMPLES && STATE.posSignal.length % 30 === 0) {
performHybridAnalysis().then(result => {
if (result) updateUI(result);
});
}
}
}
if (STATE.isAnalyzing) {
requestAnimationFrame(() => {
STATE.faceMesh.send({ image: E.webcam });
});
}
}

async function startAnalysis() {
STATE.isAnalyzing = true;
STATE.startTime = Date.now();
STATE.rSignal = [];
STATE.gSignal = [];
STATE.bSignal = [];
STATE.posSignal = [];
STATE.depthHistory = [];
STATE.embeddings = [];
E.analyzeBtn.disabled = true;
E.statusDot.className = 'status-dot dot-analyzing';
E.statusText.textContent = 'ANALYZING';
E.videoContainer.classList.add('analyzing');
const methodRadios = document.getElementsByName('detectionMethod');
for (const radio of methodRadios) {
if (radio.checked) {
STATE.detectionMethod = radio.value;
E.currentMethod.textContent = radio.nextElementSibling.textContent;
break;
}
}
STATE.metricsInterval = setInterval(() => {
const elapsed = (Date.now() - STATE.startTime) / 1000;
E.duration.textContent = elapsed.toFixed(1) + 's';
}, 100);
STATE.faceMesh.send({ image: E.webcam });
showAlert('Analysis started!', 'success');
}

function stopAnalysis() {
STATE.isAnalyzing = false;
if (STATE.metricsInterval) {
clearInterval(STATE.metricsInterval);
STATE.metricsInterval = null;
}
if (STATE.videoStream) {
STATE.videoStream.getTracks().forEach(track => track.stop());
STATE.videoStream = null;
}
E.webcam.srcObject = null;
E.startBtn.disabled = false;
E.analyzeBtn.disabled = true;
E.stopBtn.disabled = true;
E.statusDot.className = 'status-dot dot-idle';
E.statusText.textContent = 'STOPPED';
E.videoContainer.classList.remove('analyzing', 'verified', 'rejected');
showAlert('Analysis stopped', 'warning');
}

// ================================================================================
// EVENT LISTENERS
// ================================================================================
E.startBtn.addEventListener('click', startCamera);
E.analyzeBtn.addEventListener('click', startAnalysis);
E.stopBtn.addEventListener('click', stopAnalysis);

// ================================================================================
// INITIALIZATION
// ================================================================================
window.addEventListener('load', () => {
E.loadingOverlay.style.display = 'flex';
E.loadTitle.textContent = 'Loading Neural Network...';
E.loadText.textContent = 'Initializing...';
LOG.add('üöÄ Application starting...', 'info');
loadNeuralModel().finally(() => {
setTimeout(() => {
E.loadingOverlay.style.display = 'none';
LOG.add('‚úÖ Application ready!', 'success');
}, 1000);
});
});
</script>
</body>
</html>